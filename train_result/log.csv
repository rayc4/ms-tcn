epoch,lr,train_loss
0.0,0.0005,2015.9943161010742
1.0,0.0005,866.216251373291
2.0,0.0005,439.1971607208252
3.0,0.0005,248.26224517822266
4.0,0.0005,180.92829704284668
5.0,0.0005,141.52311038970947
6.0,0.0005,110.37854433059692
7.0,0.0005,118.41500854492188
8.0,0.0005,116.85881233215332
9.0,0.0005,72.13289880752563
10.0,0.0005,84.25616836547852
11.0,0.0005,111.76060152053833
12.0,0.0005,120.14716958999634
13.0,0.0005,72.71037983894348
14.0,0.0005,65.13128018379211
15.0,0.0005,55.676862359046936
16.0,0.0005,39.95101296901703
17.0,0.0005,42.70315432548523
18.0,0.0005,48.605472564697266
19.0,0.0005,43.70067381858826
20.0,0.0005,39.947651743888855
21.0,0.0005,39.0434330701828
22.0,0.0005,22.730678915977478
23.0,0.0005,25.41520130634308
24.0,0.0005,39.56182074546814
25.0,0.0005,37.12254011631012
26.0,0.0005,42.28592765331268
27.0,0.0005,30.562130361795425
28.0,0.0005,28.913557529449463
29.0,0.0005,41.060645043849945
30.0,0.0005,31.881254136562347
31.0,0.0005,30.340861439704895
32.0,0.0005,29.856408715248108
33.0,0.0005,29.37077969312668
34.0,0.0005,22.729509323835373
35.0,0.0005,27.545128285884857
36.0,0.0005,60.37257969379425
37.0,0.0005,31.49336838722229
38.0,0.0005,54.728113412857056
39.0,0.0005,33.67190074920654
40.0,0.0005,34.02541023492813
41.0,0.0005,27.043140530586243
42.0,0.0005,24.706939578056335
43.0,0.0005,25.097124993801117
44.0,0.0005,25.539081156253815
45.0,0.0005,52.993392288684845
46.0,0.0005,45.871113538742065
47.0,0.0005,21.933756053447723
48.0,0.0005,30.041398882865906
49.0,0.0005,27.37460023164749
